## Linear Regression 
						
- Linear Regression means predicting values of one variable from the values of second variable. 

- The variable we are predicting is called the criterion variable and is generally referred to as Y. 

- The variable we are basing our predictions is called the predictor variable and is generally referred to as X. 

- When there is only one predictor variable, the prediction method is called simple regression.

- The aim of linear regression is to finding the best-fitting straight line through the points. The best-fitting line is called a regression line.

- hθ(X) = θ0 + θ1.X
The above equation is hypothesis equation

where:
hθ(X) is nothing but the value Y (which we are going to predicate) for particular X (means Y is a linear function of X)

θ0 is a constant

θ1 is  the regression coefficient

X is value of the independent variable


### Linear Regression line has the following properties:

- The line minimizes the sum of squared differences between observed values (the Y values) and predicted values (the hθ(X) values computed from the regression equation).

- The regression line passes through the mean of the X values (x) and through the mean of the Y values (hθ(x)).

- The regression constant (θ0) is equal to the y intercept of the regression line.

- The regression coefficient (θ1) is the average change in the dependent variable (Y) for a unit change in the independent variable (X). It is the slope of the regression line.

- The least squares regression line is the only straight line that has all of these properties.
